<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Chat Assistant</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Inter', 'Segoe UI', system-ui, -apple-system, sans-serif;
            background: linear-gradient(135deg, #0f0f23 0%, #1a1a2e 50%, #16213e 100%);
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            padding: 20px;
        }

        .container {
            width: 100%;
            max-width: 600px;
            background: rgba(15, 15, 35, 0.95);
            border-radius: 24px;
            box-shadow: 0 8px 32px rgba(31, 38, 135, 0.37);
            backdrop-filter: blur(10px);
            overflow: hidden;
            border: 1px solid rgba(79, 209, 197, 0.18);
        }

        .header {
            background: linear-gradient(135deg, #1e3a5f 0%, #2a5298 100%);
            color: #4fd1c5;
            padding: 30px;
            text-align: center;
            border-bottom: 1px solid rgba(79, 209, 197, 0.3);
        }

        .header h1 {
            font-size: 28px;
            margin-bottom: 8px;
            font-weight: 600;
            letter-spacing: 0.5px;
            color: #ffffff;
        }

        .header p {
            opacity: 0.9;
            font-size: 14px;
            color: #4fd1c5;
            font-weight: 400;
        }

        .chat-container {
            height: 400px;
            overflow-y: auto;
            padding: 20px;
            background: #0f0f23;
        }

        .message {
            margin-bottom: 16px;
            display: flex;
            gap: 12px;
            animation: slideIn 0.3s ease-out;
        }

        @keyframes slideIn {
            from {
                opacity: 0;
                transform: translateY(10px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        .message.user {
            flex-direction: row-reverse;
        }

        .message-avatar {
            width: 40px;
            height: 40px;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 20px;
            flex-shrink: 0;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            box-shadow: 0 4px 12px rgba(102, 126, 234, 0.3);
        }

        .message.user .message-avatar {
            background: linear-gradient(135deg, #4fd1c5 0%, #3182ce 100%);
        }

        .message.assistant .message-avatar {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        }

        .message-content {
            max-width: 70%;
            padding: 14px 18px;
            border-radius: 16px;
            word-wrap: break-word;
            font-family: 'Inter', sans-serif;
            font-size: 14px;
            line-height: 1.5;
        }

        .message.user .message-content {
            background: linear-gradient(135deg, rgba(79, 209, 197, 0.15) 0%, rgba(49, 130, 206, 0.15) 100%);
            color: #e2e8f0;
            border: 1px solid rgba(79, 209, 197, 0.3);
        }

        .message.assistant .message-content {
            background: rgba(30, 58, 95, 0.3);
            color: #e2e8f0;
            border: 1px solid rgba(102, 126, 234, 0.2);
        }

        .streaming-text {
            display: inline;
        }

        .cursor {
            display: inline-block;
            width: 2px;
            height: 1em;
            background: #4fd1c5;
            margin-left: 2px;
            animation: blink 1s infinite;
        }

        @keyframes blink {
            0%, 50% { opacity: 1; }
            51%, 100% { opacity: 0; }
        }

        .loading-dots {
            display: inline-flex;
            gap: 4px;
            align-items: center;
        }

        .loading-dots span {
            width: 8px;
            height: 8px;
            border-radius: 50%;
            background: #4fd1c5;
            animation: bounce 1.4s infinite ease-in-out;
        }

        .loading-dots span:nth-child(1) {
            animation-delay: -0.32s;
        }

        .loading-dots span:nth-child(2) {
            animation-delay: -0.16s;
        }

        @keyframes bounce {
            0%, 80%, 100% {
                transform: scale(0);
                opacity: 0.5;
            }
            40% {
                transform: scale(1);
                opacity: 1;
            }
        }

        .waiting-message {
            color: #cbd5e0;
            font-style: italic;
        }

        .controls {
            padding: 24px;
            background: rgba(15, 15, 35, 0.8);
            border-top: 1px solid rgba(79, 209, 197, 0.2);
            display: flex;
            flex-direction: column;
            gap: 14px;
            align-items: center;
        }

        .record-button {
            width: 72px;
            height: 72px;
            border-radius: 50%;
            border: none;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            font-size: 32px;
            cursor: pointer;
            transition: all 0.3s ease;
            box-shadow: 0 8px 24px rgba(102, 126, 234, 0.4);
            display: flex;
            align-items: center;
            justify-content: center;
        }

        .record-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 12px 32px rgba(102, 126, 234, 0.6);
        }

        .record-button:active {
            transform: translateY(0);
        }

        .record-button.recording {
            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
            animation: pulse 1.5s ease-in-out infinite;
        }

        .record-button:disabled {
            opacity: 0.6;
            cursor: not-allowed;
        }

        @keyframes pulse {
            0%, 100% {
                box-shadow: 0 8px 24px rgba(245, 87, 108, 0.4);
            }
            50% {
                box-shadow: 0 8px 40px rgba(245, 87, 108, 0.8);
            }
        }

        .status {
            font-size: 13px;
            color: #a0aec0;
            text-align: center;
            min-height: 20px;
            font-weight: 500;
        }

        .status.active {
            color: #4fd1c5;
            font-weight: 600;
        }

        .error {
            background: rgba(254, 178, 178, 0.1);
            color: #fc8181;
            padding: 12px 16px;
            border-radius: 12px;
            margin: 12px 20px;
            font-size: 13px;
            border: 1px solid rgba(245, 87, 108, 0.3);
        }

        .chat-container::-webkit-scrollbar {
            width: 6px;
        }

        .chat-container::-webkit-scrollbar-track {
            background: rgba(15, 15, 35, 0.5);
        }

        .chat-container::-webkit-scrollbar-thumb {
            background: linear-gradient(180deg, #667eea 0%, #764ba2 100%);
            border-radius: 3px;
        }

        .chat-container::-webkit-scrollbar-thumb:hover {
            background: linear-gradient(180deg, #4fd1c5 0%, #3182ce 100%);
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>üéôÔ∏è Voice Assistant</h1>
            <p>Press the button and speak your message</p>
        </div>

        <div class="chat-container" id="chatContainer">
            <div class="message assistant">
                <div class="message-avatar">ü§ñ</div>
                <div class="message-content">
                    Hi! I'm your voice assistant. Press the microphone button below and start speaking!
                </div>
            </div>
        </div>

        <div class="controls">
            <button class="record-button" id="recordButton">
                üé§
            </button>
            <div class="status" id="status">Click to start recording</div>
        </div>
    </div>

    <script>
        let mediaRecorder;
        let audioChunks = [];
        let isRecording = false;
        let currentAudio = null;
        let silenceTimer = null;
        let audioContext = null;
        let analyser = null;
        let isProcessing = false;
        let autoRecordEnabled = true;
        let audioStream = null;

        const recordButton = document.getElementById('recordButton');
        const statusDiv = document.getElementById('status');
        const chatContainer = document.getElementById('chatContainer');

        const SILENCE_THRESHOLD = 0.01;
        const SILENCE_DURATION = 2000;
        const INITIAL_SILENCE_DURATION = 3000;
        let hasDetectedSpeech = false;
        let initialSilenceTimer = null;

        recordButton.addEventListener('click', toggleRecording);

        async function toggleRecording() {
            if (isProcessing) return;
            
            if (!isRecording) {
                await startRecording();
            } else {
                stopRecording();
            }
        }

        async function startRecording() {
            try {
                audioStream = await navigator.mediaDevices.getUserMedia({ audio: true });
                
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                analyser = audioContext.createAnalyser();
                const source = audioContext.createMediaStreamSource(audioStream);
                source.connect(analyser);
                analyser.fftSize = 2048;
                
                mediaRecorder = new MediaRecorder(audioStream);
                audioChunks = [];
                hasDetectedSpeech = false;

                mediaRecorder.ondataavailable = (event) => {
                    audioChunks.push(event.data);
                };

                mediaRecorder.onstop = async () => {
                    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                    
                    if (audioStream) {
                        audioStream.getTracks().forEach(track => track.stop());
                        audioStream = null;
                    }
                    if (audioContext) {
                        audioContext.close();
                        audioContext = null;
                    }
                    
                    if (hasDetectedSpeech) {
                        await processAudio(audioBlob);
                    } else {
                        const processingMsg = document.getElementById('processing-msg');
                        if (processingMsg) {
                            processingMsg.remove();
                        }
                        setStatus('No speech detected', false);
                        isProcessing = false;
                        recordButton.disabled = false;
                        
                        if (autoRecordEnabled) {
                            setTimeout(() => {
                                if (!isRecording && !isProcessing) {
                                    startRecording();
                                }
                            }, 1000);
                        }
                    }
                };

                mediaRecorder.start();
                isRecording = true;
                recordButton.classList.add('recording');
                recordButton.textContent = '‚èπÔ∏è';
                setStatus('Listening... speak now', true);
                
                initialSilenceTimer = setTimeout(() => {
                    if (isRecording && !hasDetectedSpeech) {
                        console.log('Auto-stopping: No speech detected');
                        stopRecording();
                    }
                }, INITIAL_SILENCE_DURATION);
                
                monitorSilence();
            } catch (error) {
                console.error('Error accessing microphone:', error);
                showError('Microphone access denied');
            }
        }

        function monitorSilence() {
            if (!isRecording) return;
            
            const bufferLength = analyser.frequencyBinCount;
            const dataArray = new Uint8Array(bufferLength);
            analyser.getByteTimeDomainData(dataArray);
            
            let sum = 0;
            for (let i = 0; i < bufferLength; i++) {
                const normalized = (dataArray[i] - 128) / 128;
                sum += normalized * normalized;
            }
            const rms = Math.sqrt(sum / bufferLength);
            
            if (rms >= SILENCE_THRESHOLD) {
                if (!hasDetectedSpeech) {
                    hasDetectedSpeech = true;
                    console.log('Speech detected!');
                    if (initialSilenceTimer) {
                        clearTimeout(initialSilenceTimer);
                        initialSilenceTimer = null;
                    }
                }
                
                if (silenceTimer) {
                    clearTimeout(silenceTimer);
                    silenceTimer = null;
                }
            } else {
                if (hasDetectedSpeech && !silenceTimer) {
                    silenceTimer = setTimeout(() => {
                        console.log('Auto-stopping due to silence after speech');
                        stopRecording();
                    }, SILENCE_DURATION);
                }
            }
            
            if (isRecording) {
                requestAnimationFrame(monitorSilence);
            }
        }

        function stopRecording() {
            if (mediaRecorder && isRecording) {
                if (silenceTimer) {
                    clearTimeout(silenceTimer);
                    silenceTimer = null;
                }
                if (initialSilenceTimer) {
                    clearTimeout(initialSilenceTimer);
                    initialSilenceTimer = null;
                }
                
                if (hasDetectedSpeech) {
                    addProcessingMessage();
                    setStatus('Processing audio...');
                }
                
                mediaRecorder.stop();
                isRecording = false;
                recordButton.classList.remove('recording');
                recordButton.textContent = 'üé§';
            }
        }

        function addProcessingMessage() {
            const messageDiv = document.createElement('div');
            messageDiv.id = 'processing-msg';
            messageDiv.className = 'message assistant';
            messageDiv.innerHTML = `
                <div class="message-avatar">ü§ñ</div>
                <div class="message-content waiting-message">
                    <span>Processing</span>
                    <div class="loading-dots">
                        <span></span>
                        <span></span>
                        <span></span>
                    </div>
                </div>
            `;
            chatContainer.appendChild(messageDiv);
            chatContainer.scrollTop = chatContainer.scrollHeight;
        }

        async function processAudio(audioBlob) {
            try {
                isProcessing = true;
                recordButton.disabled = true;
                
                const formData = new FormData();
                formData.append('audio', audioBlob, 'recording.webm');

                const uploadResponse = await fetch('/upload-audio', {
                    method: 'POST',
                    body: formData
                });

                const uploadData = await uploadResponse.json();
                
                if (!uploadData.success) {
                    throw new Error(uploadData.error || 'Upload failed');
                }

                setStatus('Transcribing...');
                
                const processResponse = await fetch('/process-audio', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({ filename: uploadData.filename })
                });

                const processData = await processResponse.json();
                
                if (!processData.success) {
                    throw new Error(processData.error || 'Processing failed');
                }

                const processingMsg = document.getElementById('processing-msg');
                if (processingMsg) {
                    processingMsg.remove();
                }

                addMessage('user', processData.transcript, 'üë§');

                const waitingMsgId = addWaitingMessage();

                setStatus('Generating response...');
                await streamTextAndAudio(processData.response, waitingMsgId);

                setStatus('Click to start recording');
                isProcessing = false;
                recordButton.disabled = false;

            } catch (error) {
                console.error('Error processing audio:', error);
                
                const processingMsg = document.getElementById('processing-msg');
                if (processingMsg) {
                    processingMsg.remove();
                }
                
                showError('Error: ' + error.message);
                setStatus('Click to start recording');
                isProcessing = false;
                recordButton.disabled = false;
            }
        }

        function addWaitingMessage() {
            const messageDiv = document.createElement('div');
            const msgId = 'waiting-' + Date.now();
            messageDiv.id = msgId;
            messageDiv.className = 'message assistant';
            messageDiv.innerHTML = `
                <div class="message-avatar">ü§ñ</div>
                <div class="message-content waiting-message">
                    <span>Wait</span>
                    <div class="loading-dots">
                        <span></span>
                        <span></span>
                        <span></span>
                    </div>
                </div>
            `;
            chatContainer.appendChild(messageDiv);
            chatContainer.scrollTop = chatContainer.scrollHeight;
            return msgId;
        }

        function addConvertingMessage() {
            const messageDiv = document.createElement('div');
            messageDiv.id = 'converting-msg';
            messageDiv.className = 'message assistant';
            messageDiv.innerHTML = `
                <div class="message-avatar">ü§ñ</div>
                <div class="message-content waiting-message">
                    <span>Converting to speech</span>
                    <div class="loading-dots">
                        <span></span>
                        <span></span>
                        <span></span>
                    </div>
                </div>
            `;
            chatContainer.appendChild(messageDiv);
            chatContainer.scrollTop = chatContainer.scrollHeight;
        }

        async function streamTextAndAudio(text, waitingMsgId) {
            try {
                const waitingMsg = document.getElementById(waitingMsgId);
                if (waitingMsg) {
                    waitingMsg.remove();
                }
                
                // Create message container for streaming text
                const messageDiv = document.createElement('div');
                const streamMsgId = 'stream-' + Date.now();
                messageDiv.id = streamMsgId;
                messageDiv.className = 'message assistant';
                messageDiv.innerHTML = `
                    <div class="message-avatar">ü§ñ</div>
                    <div class="message-content">
                        <span class="streaming-text"></span><span class="cursor"></span>
                    </div>
                `;
                chatContainer.appendChild(messageDiv);
                chatContainer.scrollTop = chatContainer.scrollHeight;
                
                const streamingText = messageDiv.querySelector('.streaming-text');
                const cursor = messageDiv.querySelector('.cursor');
                
                // Start text streaming immediately
                let charIndex = 0;
                const streamInterval = setInterval(() => {
                    if (charIndex < text.length) {
                        streamingText.textContent += text[charIndex];
                        charIndex++;
                        chatContainer.scrollTop = chatContainer.scrollHeight;
                    } else {
                        clearInterval(streamInterval);
                        cursor.remove();
                    }
                }, 30);
                
                // Start audio streaming in parallel
                setStatus('Converting to speech...');
                
                if (currentAudio) {
                    currentAudio.pause();
                    currentAudio = null;
                }

                const response = await fetch('/stream-audio', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({ text: text })
                });

                if (!response.ok) {
                    clearInterval(streamInterval);
                    throw new Error('Audio streaming failed');
                }

                // Collect ALL audio chunks before playing
                const reader = response.body.getReader();
                const chunks = [];

                while (true) {
                    const { done, value } = await reader.read();
                    if (done) break;
                    chunks.push(value);
                }

                // Now create and play the complete audio
                const audioBlob = new Blob(chunks, { type: 'audio/mpeg' });
                const audioUrl = URL.createObjectURL(audioBlob);
                
                currentAudio = new Audio(audioUrl);
                
                setStatus('üîä Playing response...');
                
                try {
                    await currentAudio.play();
                } catch (err) {
                    console.error('Audio play error:', err);
                }

                currentAudio.onended = () => {
                    URL.revokeObjectURL(audioUrl);
                    setStatus('Click to start recording');
                    
                    if (autoRecordEnabled) {
                        setTimeout(() => {
                            if (!isRecording && !isProcessing) {
                                console.log('Auto-starting next recording...');
                                startRecording();
                            }
                        }, 800);
                    }
                };
                
                currentAudio.onerror = (err) => {
                    console.error('Audio playback error:', err);
                    URL.revokeObjectURL(audioUrl);
                    showError('Audio playback failed');
                    setStatus('Click to start recording');
                };

            } catch (error) {
                console.error('Error streaming:', error);
                
                const waitingMsg = document.getElementById(waitingMsgId);
                if (waitingMsg) {
                    waitingMsg.remove();
                }
                
                showError('Failed to stream response');
                setStatus('Click to start recording');
            }
        }

        function addMessage(type, content, avatar) {
            const messageDiv = document.createElement('div');
            messageDiv.className = `message ${type}`;
            messageDiv.innerHTML = `
                <div class="message-avatar">${avatar}</div>
                <div class="message-content">${content}</div>
            `;
            chatContainer.appendChild(messageDiv);
            chatContainer.scrollTop = chatContainer.scrollHeight;
        }

        function setStatus(message, active = false) {
            statusDiv.textContent = message;
            if (active) {
                statusDiv.classList.add('active');
            } else {
                statusDiv.classList.remove('active');
            }
        }

        function showError(message) {
            const errorDiv = document.createElement('div');
            errorDiv.className = 'error';
            errorDiv.textContent = message;
            chatContainer.appendChild(errorDiv);
            chatContainer.scrollTop = chatContainer.scrollHeight;
            
            setTimeout(() => {
                errorDiv.remove();
            }, 5000);
        }

        document.addEventListener('keydown', (e) => {
            if (e.code === 'Space' && e.target === document.body && !isProcessing) {
                e.preventDefault();
                if (!isRecording) {
                    startRecording();
                }
            }
        });

        document.addEventListener('keyup', (e) => {
            if (e.code === 'Space' && isRecording) {
                e.preventDefault();
                stopRecording();
            }
        });
    </script>
</body>
</html> 